{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer-based Sudoku Solver\n",
        "\n",
        "This notebook implements a Transformer-based Sudoku solver with positional embeddings.\n",
        "\n",
        "Key improvements over the LSTM version:\n",
        "1. **Transformer Architecture**: Better at capturing global dependencies (row, column, box constraints).\n",
        "2. **Positional Embeddings**: Explicit row, column, and 3x3 box position encodings.\n",
        "3. **Learning Rate Scheduling**: OneCycleLR with warmup.\n",
        "4. **Gradient Clipping**: Prevents exploding gradients.\n",
        "5. **Label Smoothing**: Reduces overconfidence and improves generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.utils.data import (\n",
        "    DataLoader,\n",
        "    Dataset,\n",
        ")\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Processing\n",
        "\n",
        "Functions to download, augment, and save the dataset as binary files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "def shuffle_sudoku(board_flat, solution_flat):\n",
        "    \"\"\"Apply valid Sudoku transformations (permutations) to a board and solution.\"\"\"\n",
        "    board = board_flat.reshape(9, 9)\n",
        "    sol = solution_flat.reshape(9, 9)\n",
        "\n",
        "    # 1. Permute digits (1-9)\n",
        "    digit_map = np.arange(10)\n",
        "    digit_map[1:] = np.random.permutation(np.arange(1, 10))\n",
        "\n",
        "    # 2. Random Transpose\n",
        "    if np.random.rand() < 0.5:\n",
        "        board = board.T\n",
        "        sol = sol.T\n",
        "\n",
        "    # 3. Permute Bands (groups of 3 rows)\n",
        "    bands = np.random.permutation(3)\n",
        "    row_perm = np.concatenate([b * 3 + np.random.permutation(3) for b in bands])\n",
        "\n",
        "    # 4. Permute Stacks (groups of 3 cols)\n",
        "    stacks = np.random.permutation(3)\n",
        "    col_perm = np.concatenate([s * 3 + np.random.permutation(3) for s in stacks])\n",
        "\n",
        "    # Apply permutations\n",
        "    board = board[row_perm, :][:, col_perm]\n",
        "    sol = sol[row_perm, :][:, col_perm]\n",
        "\n",
        "    # Map digits\n",
        "    board = digit_map[board]\n",
        "    sol = digit_map[sol]\n",
        "\n",
        "    return board.flatten(), sol.flatten()\n",
        "\n",
        "\n",
        "def preprocess_dataset(output_dir='data/processed', num_aug=1):\n",
        "    \"\"\"Download, filter, augment, and save dataset as .npy.\"\"\"\n",
        "    if os.path.exists(output_dir):\n",
        "        print(f'Dataset already exists at {output_dir}. Skipping generation.')\n",
        "        return\n",
        "\n",
        "    print('Loading dataset from HuggingFace...')\n",
        "    ds = load_dataset('sapientinc/sudoku-extreme')\n",
        "\n",
        "    # Filter easy sources\n",
        "    easy_sources = ['puzzles0_kaggle', 'puzzles1_unbiased', 'puzzles2_17_clue']\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for split in ['train', 'test']:\n",
        "        print(f'Processing {split} split...')\n",
        "        split_ds = ds[split].filter(lambda x: x['source'] in easy_sources)\n",
        "\n",
        "        questions = []\n",
        "        answers = []\n",
        "\n",
        "        print('Converting to integers and augmenting...')\n",
        "        for item in tqdm(split_ds):\n",
        "            q = np.array(\n",
        "                [0 if c == '.' else int(c) for c in item['question']],\n",
        "                dtype=np.uint8,\n",
        "            )\n",
        "            a = np.array([int(c) for c in item['answer']], dtype=np.uint8)\n",
        "\n",
        "            questions.append(q)\n",
        "            answers.append(a)\n",
        "\n",
        "            # Augmentations (only for train)\n",
        "            if split == 'train' and num_aug > 0:\n",
        "                for _ in range(num_aug):\n",
        "                    q_aug, a_aug = shuffle_sudoku(q, a)\n",
        "                    questions.append(q_aug)\n",
        "                    answers.append(a_aug)\n",
        "\n",
        "        q_arr = np.array(questions, dtype=np.uint8)\n",
        "        a_arr = np.array(answers, dtype=np.uint8)\n",
        "\n",
        "        print(f'Saving {len(q_arr)} samples to {output_dir}...')\n",
        "        np.save(os.path.join(output_dir, f'{split}_questions.npy'), q_arr)\n",
        "        np.save(os.path.join(output_dir, f'{split}_answers.npy'), a_arr)\n",
        "\n",
        "\n",
        "# Run preprocessing (will skip if already exists)\n",
        "preprocess_dataset(num_aug=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Class\n",
        "\n",
        "Loads data directly from `.npy` files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FastSudokuDataset(Dataset):\n",
        "    \"\"\"Fast Sudoku dataset loading from preprocessed .npy files.\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir, split):\n",
        "        \"\"\"Initialize the dataset.\n",
        "\n",
        "        Args:\n",
        "            data_dir: Directory containing the .npy files.\n",
        "            split: Either 'train' or 'test'.\n",
        "        \"\"\"\n",
        "        self.questions = np.load(os.path.join(data_dir, f'{split}_questions.npy'))\n",
        "        self.answers = np.load(os.path.join(data_dir, f'{split}_answers.npy'))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        q = self.questions[idx].astype(np.int64)\n",
        "        a = self.answers[idx].astype(np.int64)\n",
        "\n",
        "        # Create mask (where q was 0 = unknown cell)\n",
        "        mask = q == 0\n",
        "\n",
        "        # Target for Loss: PyTorch CrossEntropy expects 0-8 for classes.\n",
        "        # Our answers are 1-9, so we subtract 1.\n",
        "        target = a - 1\n",
        "\n",
        "        return {\n",
        "            'question': torch.from_numpy(q),\n",
        "            'answer': torch.from_numpy(target),\n",
        "            'mask': torch.from_numpy(mask),\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Transformer Model with Positional Embeddings\n",
        "\n",
        "Key features:\n",
        "- **Value Embedding**: Maps cell values (0-9) to hidden dimension.\n",
        "- **Row/Column/Box Embeddings**: Encode spatial position in the 9x9 grid.\n",
        "- **Transformer Encoder**: Self-attention captures global dependencies.\n",
        "\n",
        "The positional embeddings help the model understand Sudoku constraints:\n",
        "- Row embedding: cells in the same row share the same row index.\n",
        "- Column embedding: cells in the same column share the same column index.\n",
        "- Box embedding: cells in the same 3x3 box share the same box index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SudokuTransformer(nn.Module):\n",
        "    \"\"\"Transformer-based Sudoku solver with positional embeddings.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size=256,\n",
        "        num_layers=6,\n",
        "        num_heads=8,\n",
        "        dropout=0.1,\n",
        "    ):\n",
        "        \"\"\"Initialize the Transformer model.\n",
        "\n",
        "        Args:\n",
        "            hidden_size: Dimension of embeddings and transformer hidden states.\n",
        "            num_layers: Number of transformer encoder layers.\n",
        "            num_heads: Number of attention heads.\n",
        "            dropout: Dropout probability.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Value embedding: 10 possible values (0=unknown, 1-9=digits)\n",
        "        self.value_embed = nn.Embedding(10, hidden_size)\n",
        "\n",
        "        # Positional embeddings for Sudoku structure\n",
        "        self.row_embed = nn.Embedding(9, hidden_size)\n",
        "        self.col_embed = nn.Embedding(9, hidden_size)\n",
        "        self.box_embed = nn.Embedding(9, hidden_size)\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_size,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_size * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            activation='gelu',\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "\n",
        "        # Output layer: 9 classes (digits 1-9)\n",
        "        self.fc = nn.Linear(hidden_size, 9)\n",
        "\n",
        "        # Precompute position indices (constant, not learned)\n",
        "        # For a 9x9 grid flattened to 81 positions:\n",
        "        # - row_idx[i] = i // 9 (which row, 0-8)\n",
        "        # - col_idx[i] = i % 9 (which column, 0-8)\n",
        "        # - box_idx[i] = (i // 9 // 3) * 3 + (i % 9 // 3) (which 3x3 box, 0-8)\n",
        "        row_idx = torch.arange(81) // 9\n",
        "        col_idx = torch.arange(81) % 9\n",
        "        box_idx = (torch.arange(81) // 9 // 3) * 3 + (torch.arange(81) % 9 // 3)\n",
        "\n",
        "        self.register_buffer('row_idx', row_idx)\n",
        "        self.register_buffer('col_idx', col_idx)\n",
        "        self.register_buffer('box_idx', box_idx)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch, 81) with values 0-9.\n",
        "\n",
        "        Returns:\n",
        "            Logits of shape (batch, 81, 9).\n",
        "        \"\"\"\n",
        "        # Value embedding: (batch, 81) -> (batch, 81, hidden_size)\n",
        "        val_emb = self.value_embed(x)\n",
        "\n",
        "        # Position embeddings: (81, hidden_size) each, broadcasted to batch\n",
        "        pos_emb = (\n",
        "            self.row_embed(self.row_idx)\n",
        "            + self.col_embed(self.col_idx)\n",
        "            + self.box_embed(self.box_idx)\n",
        "        )\n",
        "\n",
        "        # Combine value and position: (batch, 81, hidden_size)\n",
        "        x = val_emb + pos_emb\n",
        "\n",
        "        # Transformer: (batch, 81, hidden_size)\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        # Output: (batch, 81, 9)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training Utilities\n",
        "\n",
        "Loss function, accuracy metrics, and training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def masked_loss(preds, targets, mask, label_smoothing=0.1):\n",
        "    \"\"\"Compute CrossEntropyLoss only on masked (unknown) cells.\n",
        "\n",
        "    Args:\n",
        "        preds: Model output logits, shape (batch, 81, 9).\n",
        "        targets: Target class indices, shape (batch, 81).\n",
        "        mask: Boolean mask, shape (batch, 81). True = compute loss.\n",
        "        label_smoothing: Label smoothing factor for regularization.\n",
        "\n",
        "    Returns:\n",
        "        Scalar loss value.\n",
        "    \"\"\"\n",
        "    loss = F.cross_entropy(\n",
        "        preds.reshape(-1, 9),\n",
        "        targets.reshape(-1),\n",
        "        reduction='none',\n",
        "        label_smoothing=label_smoothing,\n",
        "    )\n",
        "    loss = loss.reshape(targets.shape)\n",
        "    masked = loss * mask.float()\n",
        "    return masked.sum() / (mask.sum() + 1e-6)\n",
        "\n",
        "\n",
        "def compute_accuracy(predictions, targets, mask):\n",
        "    \"\"\"Compute cell-level and puzzle-level accuracy.\n",
        "\n",
        "    Args:\n",
        "        predictions: Model output logits, shape (batch, 81, 9).\n",
        "        targets: Target class indices, shape (batch, 81).\n",
        "        mask: Boolean mask, shape (batch, 81). True = cell needs prediction.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (cell_accuracy, puzzle_accuracy).\n",
        "    \"\"\"\n",
        "    predicted_classes = predictions.argmax(dim=-1)\n",
        "\n",
        "    # Cell accuracy: correct predictions among masked cells\n",
        "    correct = (predicted_classes == targets) & mask\n",
        "    cell_accuracy = correct.sum().float() / (mask.sum().float() + 1e-6)\n",
        "\n",
        "    # Puzzle accuracy: all masked cells correct for each puzzle\n",
        "    correct_per_puzzle = correct.sum(dim=1)\n",
        "    masked_per_puzzle = mask.sum(dim=1)\n",
        "    puzzles_solved = (correct_per_puzzle == masked_per_puzzle).float()\n",
        "    puzzle_accuracy = puzzles_solved.mean()\n",
        "\n",
        "    return cell_accuracy.item(), puzzle_accuracy.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer, scheduler, scaler, device, max_grad_norm=1.0):\n",
        "    \"\"\"Train for one epoch.\n",
        "\n",
        "    Args:\n",
        "        model: The model to train.\n",
        "        loader: DataLoader for training data.\n",
        "        optimizer: Optimizer instance.\n",
        "        scheduler: Learning rate scheduler.\n",
        "        scaler: GradScaler for mixed precision (or None).\n",
        "        device: Device to train on.\n",
        "        max_grad_norm: Maximum gradient norm for clipping.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with loss, cell_accuracy, puzzle_accuracy.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_cell_acc = 0\n",
        "    total_puzzle_acc = 0\n",
        "    num_batches = 0\n",
        "    pbar = tqdm(loader)\n",
        "\n",
        "    for batch in pbar:\n",
        "        q = batch['question'].to(device)\n",
        "        a = batch['answer'].to(device)\n",
        "        m = batch['mask'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed Precision Training\n",
        "        if device.type == 'cuda' and scaler is not None:\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                preds = model(q)\n",
        "                loss = masked_loss(preds, a, m)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        elif device.type == 'mps':\n",
        "            with torch.autocast(device_type='mps', dtype=torch.float16):\n",
        "                preds = model(q)\n",
        "                loss = masked_loss(preds, a, m)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "        else:\n",
        "            preds = model(q)\n",
        "            loss = masked_loss(preds, a, m)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "        # Step scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Compute accuracy\n",
        "        with torch.no_grad():\n",
        "            cell_acc, puzzle_acc = compute_accuracy(preds, a, m)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_cell_acc += cell_acc\n",
        "        total_puzzle_acc += puzzle_acc\n",
        "        num_batches += 1\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'cell': f'{cell_acc:.2%}',\n",
        "            'puzzle': f'{puzzle_acc:.2%}',\n",
        "            'lr': f\"{scheduler.get_last_lr()[0]:.2e}\",\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        'loss': total_loss / num_batches,\n",
        "        'cell_accuracy': total_cell_acc / num_batches,\n",
        "        'puzzle_accuracy': total_puzzle_acc / num_batches,\n",
        "    }\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    \"\"\"Evaluate the model on a dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The model to evaluate.\n",
        "        loader: DataLoader for evaluation data.\n",
        "        device: Device to evaluate on.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with loss, cell_accuracy, puzzle_accuracy.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_cell_acc = 0\n",
        "    total_puzzle_acc = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in tqdm(loader, desc='Evaluating'):\n",
        "        q = batch['question'].to(device)\n",
        "        a = batch['answer'].to(device)\n",
        "        m = batch['mask'].to(device)\n",
        "\n",
        "        preds = model(q)\n",
        "        loss = masked_loss(preds, a, m, label_smoothing=0.0)\n",
        "\n",
        "        cell_acc, puzzle_acc = compute_accuracy(preds, a, m)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_cell_acc += cell_acc\n",
        "        total_puzzle_acc += puzzle_acc\n",
        "        num_batches += 1\n",
        "\n",
        "    return {\n",
        "        'loss': total_loss / num_batches,\n",
        "        'cell_accuracy': total_cell_acc / num_batches,\n",
        "        'puzzle_accuracy': total_puzzle_acc / num_batches,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training\n",
        "\n",
        "Configuration and main training loop with:\n",
        "- AdamW optimizer with weight decay\n",
        "- OneCycleLR scheduler with warmup\n",
        "- Mixed precision training\n",
        "- Gradient clipping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "BATCH_SIZE = 512\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 0.01\n",
        "NUM_EPOCHS = 20\n",
        "MAX_GRAD_NORM = 1.0\n",
        "\n",
        "# Model hyperparameters\n",
        "HIDDEN_SIZE = 256\n",
        "NUM_LAYERS = 6\n",
        "NUM_HEADS = 8\n",
        "DROPOUT = 0.1\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\n",
        "    'cuda' if torch.cuda.is_available()\n",
        "    else 'mps' if torch.backends.mps.is_available()\n",
        "    else 'cpu'\n",
        ")\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Data\n",
        "train_ds = FastSudokuDataset('data/processed', 'train')\n",
        "test_ds = FastSudokuDataset('data/processed', 'test')\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True if device.type == 'cuda' else False,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True if device.type == 'cuda' else False,\n",
        ")\n",
        "\n",
        "print(f'Train samples: {len(train_ds):,}')\n",
        "print(f'Test samples: {len(test_ds):,}')\n",
        "print(f'Train batches per epoch: {len(train_loader):,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Model\n",
        "model = SudokuTransformer(\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT,\n",
        ").to(device)\n",
        "\n",
        "# Count parameters\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Model parameters: {num_params:,}')\n",
        "\n",
        "# Compile model if available (PyTorch 2.0+, CUDA)\n",
        "if hasattr(torch, 'compile') and device.type == 'cuda':\n",
        "    print('Compiling model with torch.compile...')\n",
        "    model = torch.compile(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizer and Scheduler\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        ")\n",
        "\n",
        "# OneCycleLR: warmup -> peak -> decay\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=LEARNING_RATE,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.1,  # 10% warmup\n",
        "    anneal_strategy='cos',\n",
        ")\n",
        "\n",
        "# GradScaler for mixed precision (CUDA only)\n",
        "scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "best_puzzle_acc = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f'\\n{\"=\" * 60}')\n",
        "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}')\n",
        "    print('=' * 60)\n",
        "\n",
        "    # Train\n",
        "    train_metrics = train_epoch(\n",
        "        model, train_loader, optimizer, scheduler, scaler, device, MAX_GRAD_NORM\n",
        "    )\n",
        "    print(\n",
        "        f\"Train - Loss: {train_metrics['loss']:.4f}, \"\n",
        "        f\"Cell Acc: {train_metrics['cell_accuracy']:.2%}, \"\n",
        "        f\"Puzzle Acc: {train_metrics['puzzle_accuracy']:.2%}\"\n",
        "    )\n",
        "\n",
        "    # Evaluate every 5 epochs or on last epoch\n",
        "    if (epoch + 1) % 5 == 0 or epoch == NUM_EPOCHS - 1:\n",
        "        test_metrics = evaluate(model, test_loader, device)\n",
        "        print(\n",
        "            f\"Test  - Loss: {test_metrics['loss']:.4f}, \"\n",
        "            f\"Cell Acc: {test_metrics['cell_accuracy']:.2%}, \"\n",
        "            f\"Puzzle Acc: {test_metrics['puzzle_accuracy']:.2%}\"\n",
        "        )\n",
        "\n",
        "        # Save best model\n",
        "        if test_metrics['puzzle_accuracy'] > best_puzzle_acc:\n",
        "            best_puzzle_acc = test_metrics['puzzle_accuracy']\n",
        "            torch.save(model.state_dict(), 'best_transformer_model.pt')\n",
        "            print(f'  -> New best model saved! (Puzzle Acc: {best_puzzle_acc:.2%})')\n",
        "\n",
        "print('\\n' + '=' * 60)\n",
        "print(f'Training complete! Best puzzle accuracy: {best_puzzle_acc:.2%}')\n",
        "print('=' * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Iterative Inference (Optional)\n",
        "\n",
        "For harder puzzles, iteratively fill the most confident cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def solve_iterative(model, puzzle, device, max_iters=81):\n",
        "    \"\"\"Solve a Sudoku puzzle by iteratively filling the most confident cell.\n",
        "\n",
        "    Args:\n",
        "        model: Trained SudokuTransformer model.\n",
        "        puzzle: Tensor of shape (81,) with values 0-9 (0=unknown).\n",
        "        device: Device to run inference on.\n",
        "        max_iters: Maximum number of iterations.\n",
        "\n",
        "    Returns:\n",
        "        Solved puzzle tensor of shape (81,).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    puzzle = puzzle.clone().to(device)\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        mask = puzzle == 0\n",
        "        if not mask.any():\n",
        "            break\n",
        "\n",
        "        logits = model(puzzle.unsqueeze(0)).squeeze(0)  # (81, 9)\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        confidence, preds = probs.max(dim=-1)  # (81,)\n",
        "\n",
        "        # Mask out already-filled cells\n",
        "        confidence = confidence.masked_fill(~mask, -float('inf'))\n",
        "\n",
        "        # Fill the most confident cell\n",
        "        best_idx = confidence.argmax()\n",
        "        puzzle[best_idx] = preds[best_idx] + 1  # +1 because preds are 0-8\n",
        "\n",
        "    return puzzle\n",
        "\n",
        "\n",
        "def display_sudoku(puzzle):\n",
        "    \"\"\"Display a Sudoku puzzle in a readable format.\n",
        "\n",
        "    Args:\n",
        "        puzzle: Tensor or array of shape (81,) with values 0-9.\n",
        "    \"\"\"\n",
        "    if isinstance(puzzle, torch.Tensor):\n",
        "        puzzle = puzzle.cpu().numpy()\n",
        "\n",
        "    puzzle = puzzle.reshape(9, 9)\n",
        "    for i in range(9):\n",
        "        if i % 3 == 0 and i > 0:\n",
        "            print('-' * 21)\n",
        "        row = ''\n",
        "        for j in range(9):\n",
        "            if j % 3 == 0 and j > 0:\n",
        "                row += '| '\n",
        "            val = puzzle[i, j]\n",
        "            row += f\"{val if val > 0 else '.'} \"\n",
        "        print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Test iterative solving on a sample\n",
        "sample = test_ds[0]\n",
        "puzzle = sample['question']\n",
        "answer = sample['answer'] + 1  # Convert back to 1-9\n",
        "\n",
        "print('Original puzzle:')\n",
        "display_sudoku(puzzle)\n",
        "\n",
        "print('\\nSolved (iterative):')\n",
        "solved = solve_iterative(model, puzzle, device)\n",
        "display_sudoku(solved)\n",
        "\n",
        "print('\\nGround truth:')\n",
        "display_sudoku(answer)\n",
        "\n",
        "# Check correctness\n",
        "mask = sample['mask']\n",
        "correct = (solved.cpu() == answer)[mask].all()\n",
        "print(f'\\nCorrect: {correct}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
